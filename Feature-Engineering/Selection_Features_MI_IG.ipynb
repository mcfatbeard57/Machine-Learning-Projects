{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Selection_Features_MI_IG.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EEXdcLqXv6k_"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMGbkcLsbHCbhaTzqq0sDt1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcfatbeard57/Feature-Engineering/blob/main/Selection_Features_MI_IG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ5BNaXftY1T"
      },
      "source": [
        "## Feature Selection MI - IG\r\n",
        "Information gain - Mutual information "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhdJGoMx1mYd"
      },
      "source": [
        "Selecting Features with high MI/IG for Classificationa and Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEXdcLqXv6k_"
      },
      "source": [
        "### Theory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chX97Ihltjvv"
      },
      "source": [
        "\r\n",
        "Mutual Information\r\n",
        "MI Estimate mutual information for a discrete target variable.\r\n",
        "\r\n",
        "Mutual information (MI) between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.\r\n",
        "\r\n",
        "The function relies on nonparametric methods based on entropy estimation from k-nearest neighbors distances.\r\n",
        "\r\n",
        "Mutual information is calculated between two variables and measures the reduction in uncertainty for one variable given a known value of the other variable.\r\n",
        "\r\n",
        "Inshort\r\n",
        "\r\n",
        "A quantity called mutual information measures the amount of information one can obtain from one random variable given another.\r\n",
        "\r\n",
        "The mutual information between two random variables X and Y can be stated formally as follows:\r\n",
        "\r\n",
        "I(X ; Y) = H(X) – H(X | Y) Where I(X ; Y) is the mutual information for X and Y, H(X) is the entropy for X and H(X | Y) is the conditional entropy for X given Y. The result has the units of bits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rB7ctHGtxjf"
      },
      "source": [
        "Entropy: \r\n",
        "\r\n",
        "Information Gain: \r\n",
        "\r\n",
        "Gini Impurity:\r\n",
        "\r\n",
        "Statistical test:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egjVrVGRvpmj"
      },
      "source": [
        "### For Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAJxeN0GtYI-"
      },
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\r\n",
        "# determine the mutual information\r\n",
        "# Handle null values beforehand\r\n",
        "mutual_info = mutual_info_classif(X_train, y_train)\r\n",
        "mutual_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tZqTC1Jt82c"
      },
      "source": [
        "mutual_info = pd.Series(mutual_info)\r\n",
        "mutual_info.index = X_train.columns\r\n",
        "mutual_info.sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUnfxDtgt-mi"
      },
      "source": [
        "#let's plot the ordered mutual_info values per feature\r\n",
        "mutual_info.sort_values(ascending=False).plot.bar(figsize=(20, 8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD4SnbM7uEku"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_kEJ-vCuHoq"
      },
      "source": [
        "#No we Will select the  top 5 important features\r\n",
        "sel_five_cols = SelectKBest(mutual_info_classif, k=5)\r\n",
        "sel_five_cols.fit(X_train, y_train)\r\n",
        "X_train.columns[sel_five_cols.get_support()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-wH9SbTuEzH"
      },
      "source": [
        "Difference Between Information Gain And Mutual Information\r\n",
        "I(X ; Y) = H(X) – H(X | Y) and IG(S, a) = H(S) – H(S | a)\r\n",
        "\r\n",
        "As such, mutual information is sometimes used as a synonym for information gain. Technically, they calculate the same quantity if applied to the same data.\r\n",
        "\r\n",
        "Comparion of Univariate And Mutual Information\r\n",
        "Comparison of F-test and mutual information https://scikit-learn.org/stable/auto_examples/feature_selection/plot_f_test_vs_mi.html#sphx-glr-auto-examples-feature-selection-plot-f-test-vs-mi-py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxooI-4IvsP_"
      },
      "source": [
        "### For Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0brlYiywFD0"
      },
      "source": [
        "#### To find the numerical columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_7WPO6wuFMu"
      },
      "source": [
        "numeric_lst=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\r\n",
        "numerical_cols = list(housing_df.select_dtypes(include=numeric_lst).columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-Uc4C-DwN4T"
      },
      "source": [
        "#### Applying Mutual info method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK6Tc7JvwHkc"
      },
      "source": [
        "from sklearn.feature_selection import mutual_info_regression\r\n",
        "# determine the mutual information\r\n",
        "# Hnadle null values\r\n",
        "mutual_info = mutual_info_regression(X_train.fillna(0), y_train)\r\n",
        "mutual_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdqByBt2wbkt"
      },
      "source": [
        "# Convert it into decending series\r\n",
        "mutual_info = pd.Series(mutual_info)\r\n",
        "mutual_info.index = X_train.columns\r\n",
        "mutual_info.sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReCWAom6wdcI"
      },
      "source": [
        "# plot\r\n",
        "mutual_info.sort_values(ascending=False).plot.bar(figsize=(15,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQH50q5-wfJX"
      },
      "source": [
        "# selecting K best features\r\n",
        "from sklearn.feature_selection import SelectPercentile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs3clVHhwllX"
      },
      "source": [
        "## Selecting the top 20 percentile\r\n",
        "selected_top_columns = SelectPercentile(mutual_info_regression, percentile=20)\r\n",
        "selected_top_columns.fit(X_train.fillna(0), y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtaphZOtwoim"
      },
      "source": [
        "selected_top_columns.get_support()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIoTcO62wqSN"
      },
      "source": [
        "X_train.columns[selected_top_columns.get_support()]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}