{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pipelines.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMndaP1KsnJU4tgdrj7mkWu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcfatbeard57/Machine-Learning-Models/blob/master/Pipelines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-F10hKrqAvM"
      },
      "source": [
        "## Pipelines using sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF4Slrslp-Bn"
      },
      "source": [
        "## Pipelines Creation\n",
        "## 1. Data Preprocessing by using Standard Scaler\n",
        "## 2. Reduce Dimension using PCA\n",
        "## 3. Apply  Classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGXdv2XarxU8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VK_PPFBr1hq"
      },
      "source": [
        "pipeline_lr=Pipeline([('scalar1',StandardScaler()),\n",
        "                     ('pca1',PCA(n_components=2)),\n",
        "                     ('lr_classifier',LogisticRegression(random_state=0))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn9ArVx0r2k-"
      },
      "source": [
        "pipeline_dt=Pipeline([('scalar2',StandardScaler()),\n",
        "                     ('pca2',PCA(n_components=2)),\n",
        "                     ('dt_classifier',DecisionTreeClassifier())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDUbhkfqr3rK"
      },
      "source": [
        "pipeline_randomforest=Pipeline([('scalar3',StandardScaler()),\n",
        "                     ('pca3',PCA(n_components=2)),\n",
        "                     ('rf_classifier',RandomForestClassifier())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jokzAhGsr58L"
      },
      "source": [
        "## LEts make the list of pipelines\n",
        "pipelines = [pipeline_lr, pipeline_dt, pipeline_randomforest]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-y-2J-Sr6_D"
      },
      "source": [
        "best_accuracy=0.0\n",
        "best_classifier=0\n",
        "best_pipeline=\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_vW7rhJr8Ur"
      },
      "source": [
        "# Dictionary of pipelines and classifier types for ease of reference\n",
        "pipe_dict = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'RandomForest'}\n",
        "\n",
        "# Fit the pipelines\n",
        "for pipe in pipelines:\n",
        "\tpipe.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX8nI5Swr-ia"
      },
      "source": [
        "for i,model in enumerate(pipelines):\n",
        "    print(\"{} Test Accuracy: {}\".format(pipe_dict[i],model.score(X_test,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVbAhnVysG1p"
      },
      "source": [
        "for i,model in enumerate(pipelines):\n",
        "    if model.score(X_test,y_test)>best_accuracy:\n",
        "        best_accuracy=model.score(X_test,y_test)\n",
        "        best_pipeline=model\n",
        "        best_classifier=i\n",
        "print('Classifier with best accuracy:{}'.format(pipe_dict[best_classifier]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7-QErucsJNZ"
      },
      "source": [
        "### Pipelines Perform Hyperparameter Tuning Using Grid SearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzVtTiY0sJFJ"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAAijCaAsL3b"
      },
      "source": [
        "# Create a pipeline\n",
        "pipe = Pipeline([(\"classifier\", RandomForestClassifier())])\n",
        "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
        "grid_param = [\n",
        "                {\"classifier\": [LogisticRegression()],\n",
        "                 \"classifier__penalty\": ['l2','l1'],\n",
        "                 \"classifier__C\": np.logspace(0, 4, 10)\n",
        "                 },\n",
        "                {\"classifier\": [LogisticRegression()],\n",
        "                 \"classifier__penalty\": ['l2'],\n",
        "                 \"classifier__C\": np.logspace(0, 4, 10),\n",
        "                 \"classifier__solver\":['newton-cg','saga','sag','liblinear'] ##This solvers don't allow L1 penalty\n",
        "                 },\n",
        "                {\"classifier\": [RandomForestClassifier()],\n",
        "                 \"classifier__n_estimators\": [10, 100, 1000],\n",
        "                 \"classifier__max_depth\":[5,8,15,25,30,None],\n",
        "                 \"classifier__min_samples_leaf\":[1,2,5,10,15,100],\n",
        "                 \"classifier__max_leaf_nodes\": [2, 5,10]}]\n",
        "# create a gridsearch of the pipeline, the fit the best model\n",
        "gridsearch = GridSearchCV(pipe, grid_param, cv=5, verbose=0,n_jobs=-1) # Fit grid search\n",
        "best_model = gridsearch.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSDl2vcTsmnY"
      },
      "source": [
        "## MakePipelines In SKLearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un3-UD5Zsnzn"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36yRoqhPsqED"
      },
      "source": [
        "# Create a pipeline\n",
        "pipe = make_pipeline((RandomForestClassifier()))\n",
        "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
        "grid_param = [\n",
        "                {\"randomforestclassifier\": [RandomForestClassifier()],\n",
        "                 \"randomforestclassifier__n_estimators\": [10, 100, 1000],\n",
        "                 \"randomforestclassifier__max_depth\":[5,8,15,25,30,None],\n",
        "                 \"randomforestclassifier__min_samples_leaf\":[1,2,5,10,15,100],\n",
        "                 \"randomforestclassifier__max_leaf_nodes\": [2, 5,10]}]\n",
        "# create a gridsearch of the pipeline, the fit the best model\n",
        "gridsearch = GridSearchCV(pipe, grid_param, cv=5, verbose=0,n_jobs=-1) # Fit grid search\n",
        "best_model = gridsearch.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9KmQcS9srO_"
      },
      "source": [
        "\n",
        "best_model.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
